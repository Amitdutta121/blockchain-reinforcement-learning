{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 21:59:34,193 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/cj/2vc0x8zd5w11m7pm9q543kw80000gp/T/dask-worker-space/worker-y_63a7xr', purging\n",
      "2023-02-02 21:59:34,193 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/cj/2vc0x8zd5w11m7pm9q543kw80000gp/T/dask-worker-space/worker-r4wwkn5f', purging\n",
      "2023-02-02 21:59:34,193 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/cj/2vc0x8zd5w11m7pm9q543kw80000gp/T/dask-worker-space/worker-uggm84vk', purging\n",
      "2023-02-02 21:59:34,193 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/cj/2vc0x8zd5w11m7pm9q543kw80000gp/T/dask-worker-space/worker-h3mr672o', purging\n",
      "2023-02-02 21:59:34,194 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/cj/2vc0x8zd5w11m7pm9q543kw80000gp/T/dask-worker-space/worker-pewih9ng', purging\n",
      "2023-02-02 21:59:34,194 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/cj/2vc0x8zd5w11m7pm9q543kw80000gp/T/dask-worker-space/worker-boxph61t', purging\n",
      "2023-02-02 21:59:34,194 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/cj/2vc0x8zd5w11m7pm9q543kw80000gp/T/dask-worker-space/worker-oc9fole2', purging\n",
      "2023-02-02 21:59:34,195 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/cj/2vc0x8zd5w11m7pm9q543kw80000gp/T/dask-worker-space/worker-fi7os_d9', purging\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()  # start distributed scheduler locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv(f\"/Volumes/GoogleDrive/My Drive/blockchaindata/transaction_dump_csv/*csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['block_id', 'hash', 'time', 'size', 'weight', 'version', 'lock_time',\n",
       "       'is_coinbase', 'has_witness', 'input_count', 'output_count',\n",
       "       'input_total', 'input_total_usd', 'output_total', 'output_total_usd',\n",
       "       'fee', 'fee_usd', 'fee_per_kb', 'fee_per_kb_usd', 'fee_per_kwu',\n",
       "       'fee_per_kwu_usd', 'cdd_total'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(x):\n",
    "    return x.split(\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amitdutta/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/dask/dataframe/core.py:4158: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('time', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    }
   ],
   "source": [
    "df['time']=df['time'].apply(function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "gk = df.groupby('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gk.get_group(\"2017-01-01\").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m selected_df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfee\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock_id\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mselected_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcombined.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/dask/dataframe/core.py:1710\u001b[0m, in \u001b[0;36m_Frame.to_csv\u001b[0;34m(self, filename, **kwargs)\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See dd.to_csv docstring for more information\"\"\"\u001b[39;00m\n\u001b[1;32m   1708\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_csv\n\u001b[0;32m-> 1710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/dask/dataframe/io/csv.py:989\u001b[0m, in \u001b[0;36mto_csv\u001b[0;34m(df, filename, single_file, encoding, mode, name_function, compression, compute, scheduler, storage_options, header_first_partition_only, compute_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         compute_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m scheduler\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43mdask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompute_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/dask/base.py:599\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    596\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[1;32m    597\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 599\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/dask/threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[1;32m     87\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 89\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_get_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpack_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpack_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/dask/local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         \u001b[43mraise_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[1;32m    513\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/dask/local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/dask/local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[0;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[1;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m(\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/dask/core.py:113\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Do the actual work of collecting data and executing a function\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03mExamples\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m'foo'\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_execute_task(a, cache) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arg]\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m istask(arg):\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/dask/core.py:113\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Do the actual work of collecting data and executing a function\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03mExamples\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m'foo'\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arg]\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m istask(arg):\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/dask/bytes/core.py:192\u001b[0m, in \u001b[0;36mread_block_from_file\u001b[0;34m(lazy_file, off, bs, delimiter)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m off \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m bs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/fsspec/utils.py:266\u001b[0m, in \u001b[0;36mread_block\u001b[0;34m(f, offset, length, delimiter, split_before)\u001b[0m\n\u001b[1;32m    263\u001b[0m     length \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m    265\u001b[0m f\u001b[38;5;241m.\u001b[39mseek(offset)\n\u001b[0;32m--> 266\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m b\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/fsspec/implementations/local.py:349\u001b[0m, in \u001b[0;36mLocalFileOpener.read\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "# selected_df = df[['time','size', 'fee', 'block_id']]\n",
    "# selected_df.to_csv('combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(\"combined.csv/0000.part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Get a list of all the \".part\" files\n",
    "files = sorted(glob.glob(\"combined.csv/*.part\"))\n",
    "\n",
    "# Open the first file for writing, and write the contents of all the files to it\n",
    "with open(\"combined_files.csv\", \"w\") as outfile:\n",
    "    for filename in files:\n",
    "        with open(filename) as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"combined.csv\"\n",
    "files = [f for f in os.listdir(path) if f.endswith('.part')]\n",
    "\n",
    "df_list = [pd.read_csv(os.path.join(path, f)) for f in files]\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {1: str, 2: str, 3: str}\n",
    "sam_df = pd.read_csv(\"combined_files.csv\", dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>fee</th>\n",
       "      <th>block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51014421</th>\n",
       "      <td>2016-08-25 23:55:57</td>\n",
       "      <td>224</td>\n",
       "      <td>5180</td>\n",
       "      <td>426861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51014422</th>\n",
       "      <td>2016-08-25 23:55:57</td>\n",
       "      <td>666</td>\n",
       "      <td>15000</td>\n",
       "      <td>426861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51014423</th>\n",
       "      <td>2016-08-25 23:55:57</td>\n",
       "      <td>225</td>\n",
       "      <td>4520</td>\n",
       "      <td>426861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51014424</th>\n",
       "      <td>2016-08-25 23:55:57</td>\n",
       "      <td>371</td>\n",
       "      <td>7420</td>\n",
       "      <td>426861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51014425</th>\n",
       "      <td>2016-08-25 23:55:57</td>\n",
       "      <td>373</td>\n",
       "      <td>7460</td>\n",
       "      <td>426861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time  size    fee  block_id\n",
       "51014421  2016-08-25 23:55:57   224   5180    426861\n",
       "51014422  2016-08-25 23:55:57   666  15000    426861\n",
       "51014423  2016-08-25 23:55:57   225   4520    426861\n",
       "51014424  2016-08-25 23:55:57   371   7420    426861\n",
       "51014425  2016-08-25 23:55:57   373   7460    426861"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(x):\n",
    "    return x.split(\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sam_df['time']=sam_df['time'].apply(function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>fee</th>\n",
       "      <th>block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>391182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>813</td>\n",
       "      <td>41050</td>\n",
       "      <td>391182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>666</td>\n",
       "      <td>33600</td>\n",
       "      <td>391182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1847</td>\n",
       "      <td>31347</td>\n",
       "      <td>391182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>192</td>\n",
       "      <td>10000</td>\n",
       "      <td>391182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time  size    fee block_id\n",
       "0  2016-01-01   150      0   391182\n",
       "1  2016-01-01   813  41050   391182\n",
       "2  2016-01-01   666  33600   391182\n",
       "3  2016-01-01  1847  31347   391182\n",
       "4  2016-01-01   192  10000   391182"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "gk = sam_df.groupby('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-01 \n",
      "\n",
      "\n",
      "2016-01-02 \n",
      "\n",
      "\n",
      "2016-01-03 \n",
      "\n",
      "\n",
      "2016-01-04 \n",
      "\n",
      "\n",
      "2016-01-05 \n",
      "\n",
      "\n",
      "2016-01-06 \n",
      "\n",
      "\n",
      "2016-01-07 \n",
      "\n",
      "\n",
      "2016-01-08 \n",
      "\n",
      "\n",
      "2016-01-09 \n",
      "\n",
      "\n",
      "2016-01-10 \n",
      "\n",
      "\n",
      "2016-01-11 \n",
      "\n",
      "\n",
      "2016-01-12 \n",
      "\n",
      "\n",
      "2016-01-13 \n",
      "\n",
      "\n",
      "2016-01-14 \n",
      "\n",
      "\n",
      "2016-01-15 \n",
      "\n",
      "\n",
      "2016-01-16 \n",
      "\n",
      "\n",
      "2016-01-17 \n",
      "\n",
      "\n",
      "2016-01-18 \n",
      "\n",
      "\n",
      "2016-01-19 \n",
      "\n",
      "\n",
      "2016-01-20 \n",
      "\n",
      "\n",
      "2016-01-21 \n",
      "\n",
      "\n",
      "2016-01-22 \n",
      "\n",
      "\n",
      "2016-01-23 \n",
      "\n",
      "\n",
      "2016-01-24 \n",
      "\n",
      "\n",
      "2016-01-25 \n",
      "\n",
      "\n",
      "2016-01-26 \n",
      "\n",
      "\n",
      "2016-01-27 \n",
      "\n",
      "\n",
      "2016-01-28 \n",
      "\n",
      "\n",
      "2016-01-29 \n",
      "\n",
      "\n",
      "2016-01-30 \n",
      "\n",
      "\n",
      "2016-01-31 \n",
      "\n",
      "\n",
      "2016-02-01 \n",
      "\n",
      "\n",
      "2016-02-02 \n",
      "\n",
      "\n",
      "2016-02-03 \n",
      "\n",
      "\n",
      "2016-02-04 \n",
      "\n",
      "\n",
      "2016-02-05 \n",
      "\n",
      "\n",
      "2016-02-06 \n",
      "\n",
      "\n",
      "2016-02-07 \n",
      "\n",
      "\n",
      "2016-02-08 \n",
      "\n",
      "\n",
      "2016-02-09 \n",
      "\n",
      "\n",
      "2016-02-10 \n",
      "\n",
      "\n",
      "2016-02-11 \n",
      "\n",
      "\n",
      "2016-02-12 \n",
      "\n",
      "\n",
      "2016-02-13 \n",
      "\n",
      "\n",
      "2016-02-14 \n",
      "\n",
      "\n",
      "2016-02-15 \n",
      "\n",
      "\n",
      "2016-02-16 \n",
      "\n",
      "\n",
      "2016-02-17 \n",
      "\n",
      "\n",
      "2016-02-18 \n",
      "\n",
      "\n",
      "2016-02-19 \n",
      "\n",
      "\n",
      "2016-02-20 \n",
      "\n",
      "\n",
      "2016-02-21 \n",
      "\n",
      "\n",
      "2016-02-22 \n",
      "\n",
      "\n",
      "2016-02-23 \n",
      "\n",
      "\n",
      "2016-02-24 \n",
      "\n",
      "\n",
      "2016-02-25 \n",
      "\n",
      "\n",
      "2016-02-26 \n",
      "\n",
      "\n",
      "2016-02-27 \n",
      "\n",
      "\n",
      "2016-02-28 \n",
      "\n",
      "\n",
      "2016-02-29 \n",
      "\n",
      "\n",
      "2016-03-01 \n",
      "\n",
      "\n",
      "2016-03-02 \n",
      "\n",
      "\n",
      "2016-03-03 \n",
      "\n",
      "\n",
      "2016-03-04 \n",
      "\n",
      "\n",
      "2016-03-05 \n",
      "\n",
      "\n",
      "2016-03-06 \n",
      "\n",
      "\n",
      "2016-03-07 \n",
      "\n",
      "\n",
      "2016-03-08 \n",
      "\n",
      "\n",
      "2016-03-09 \n",
      "\n",
      "\n",
      "2016-03-10 \n",
      "\n",
      "\n",
      "2016-03-11 \n",
      "\n",
      "\n",
      "2016-03-12 \n",
      "\n",
      "\n",
      "2016-03-13 \n",
      "\n",
      "\n",
      "2016-03-14 \n",
      "\n",
      "\n",
      "2016-03-15 \n",
      "\n",
      "\n",
      "2016-03-16 \n",
      "\n",
      "\n",
      "2016-03-17 \n",
      "\n",
      "\n",
      "2016-03-18 \n",
      "\n",
      "\n",
      "2016-03-19 \n",
      "\n",
      "\n",
      "2016-03-20 \n",
      "\n",
      "\n",
      "2016-03-21 \n",
      "\n",
      "\n",
      "2016-03-22 \n",
      "\n",
      "\n",
      "2016-03-23 \n",
      "\n",
      "\n",
      "2016-03-24 \n",
      "\n",
      "\n",
      "2016-03-25 \n",
      "\n",
      "\n",
      "2016-03-26 \n",
      "\n",
      "\n",
      "2016-03-27 \n",
      "\n",
      "\n",
      "2016-03-28 \n",
      "\n",
      "\n",
      "2016-03-29 \n",
      "\n",
      "\n",
      "2016-03-30 \n",
      "\n",
      "\n",
      "2016-03-31 \n",
      "\n",
      "\n",
      "2016-04-01 \n",
      "\n",
      "\n",
      "2016-04-02 \n",
      "\n",
      "\n",
      "2016-04-03 \n",
      "\n",
      "\n",
      "2016-04-04 \n",
      "\n",
      "\n",
      "2016-04-05 \n",
      "\n",
      "\n",
      "2016-04-06 \n",
      "\n",
      "\n",
      "2016-04-07 \n",
      "\n",
      "\n",
      "2016-04-08 \n",
      "\n",
      "\n",
      "2016-04-09 \n",
      "\n",
      "\n",
      "2016-04-10 \n",
      "\n",
      "\n",
      "2016-04-11 \n",
      "\n",
      "\n",
      "2016-04-12 \n",
      "\n",
      "\n",
      "2016-04-13 \n",
      "\n",
      "\n",
      "2016-04-14 \n",
      "\n",
      "\n",
      "2016-04-15 \n",
      "\n",
      "\n",
      "2016-04-16 \n",
      "\n",
      "\n",
      "2016-04-17 \n",
      "\n",
      "\n",
      "2016-04-18 \n",
      "\n",
      "\n",
      "2016-04-19 \n",
      "\n",
      "\n",
      "2016-04-20 \n",
      "\n",
      "\n",
      "2016-04-21 \n",
      "\n",
      "\n",
      "2016-04-22 \n",
      "\n",
      "\n",
      "2016-04-23 \n",
      "\n",
      "\n",
      "2016-04-24 \n",
      "\n",
      "\n",
      "2016-04-25 \n",
      "\n",
      "\n",
      "2016-04-26 \n",
      "\n",
      "\n",
      "2016-04-27 \n",
      "\n",
      "\n",
      "2016-04-28 \n",
      "\n",
      "\n",
      "2016-04-29 \n",
      "\n",
      "\n",
      "2016-04-30 \n",
      "\n",
      "\n",
      "2016-05-01 \n",
      "\n",
      "\n",
      "2016-05-02 \n",
      "\n",
      "\n",
      "2016-05-03 \n",
      "\n",
      "\n",
      "2016-05-04 \n",
      "\n",
      "\n",
      "2016-05-05 \n",
      "\n",
      "\n",
      "2016-05-06 \n",
      "\n",
      "\n",
      "2016-05-07 \n",
      "\n",
      "\n",
      "2016-05-08 \n",
      "\n",
      "\n",
      "2016-05-09 \n",
      "\n",
      "\n",
      "2016-05-10 \n",
      "\n",
      "\n",
      "2016-05-11 \n",
      "\n",
      "\n",
      "2016-05-12 \n",
      "\n",
      "\n",
      "2016-05-13 \n",
      "\n",
      "\n",
      "2016-05-14 \n",
      "\n",
      "\n",
      "2016-05-15 \n",
      "\n",
      "\n",
      "2016-05-16 \n",
      "\n",
      "\n",
      "2016-05-17 \n",
      "\n",
      "\n",
      "2016-05-18 \n",
      "\n",
      "\n",
      "2016-05-19 \n",
      "\n",
      "\n",
      "2016-05-20 \n",
      "\n",
      "\n",
      "2016-05-21 \n",
      "\n",
      "\n",
      "2016-05-22 \n",
      "\n",
      "\n",
      "2016-05-23 \n",
      "\n",
      "\n",
      "2016-05-24 \n",
      "\n",
      "\n",
      "2016-05-25 \n",
      "\n",
      "\n",
      "2016-05-26 \n",
      "\n",
      "\n",
      "2016-05-27 \n",
      "\n",
      "\n",
      "2016-05-28 \n",
      "\n",
      "\n",
      "2016-05-29 \n",
      "\n",
      "\n",
      "2016-05-30 \n",
      "\n",
      "\n",
      "2016-05-31 \n",
      "\n",
      "\n",
      "2016-06-01 \n",
      "\n",
      "\n",
      "2016-06-02 \n",
      "\n",
      "\n",
      "2016-06-03 \n",
      "\n",
      "\n",
      "2016-06-04 \n",
      "\n",
      "\n",
      "2016-06-05 \n",
      "\n",
      "\n",
      "2016-06-06 \n",
      "\n",
      "\n",
      "2016-06-07 \n",
      "\n",
      "\n",
      "2016-06-08 \n",
      "\n",
      "\n",
      "2016-06-09 \n",
      "\n",
      "\n",
      "2016-06-10 \n",
      "\n",
      "\n",
      "2016-06-11 \n",
      "\n",
      "\n",
      "2016-06-12 \n",
      "\n",
      "\n",
      "2016-06-13 \n",
      "\n",
      "\n",
      "2016-06-14 \n",
      "\n",
      "\n",
      "2016-06-15 \n",
      "\n",
      "\n",
      "2016-06-16 \n",
      "\n",
      "\n",
      "2016-06-17 \n",
      "\n",
      "\n",
      "2016-06-18 \n",
      "\n",
      "\n",
      "2016-06-19 \n",
      "\n",
      "\n",
      "2016-06-20 \n",
      "\n",
      "\n",
      "2016-06-21 \n",
      "\n",
      "\n",
      "2016-06-22 \n",
      "\n",
      "\n",
      "2016-06-23 \n",
      "\n",
      "\n",
      "2016-06-24 \n",
      "\n",
      "\n",
      "2016-06-25 \n",
      "\n",
      "\n",
      "2016-06-26 \n",
      "\n",
      "\n",
      "2016-06-27 \n",
      "\n",
      "\n",
      "2016-06-28 \n",
      "\n",
      "\n",
      "2016-06-29 \n",
      "\n",
      "\n",
      "2016-06-30 \n",
      "\n",
      "\n",
      "2016-07-01 \n",
      "\n",
      "\n",
      "2016-07-02 \n",
      "\n",
      "\n",
      "2016-07-03 \n",
      "\n",
      "\n",
      "2016-07-04 \n",
      "\n",
      "\n",
      "2016-07-05 \n",
      "\n",
      "\n",
      "2016-07-06 \n",
      "\n",
      "\n",
      "2016-07-07 \n",
      "\n",
      "\n",
      "2016-07-08 \n",
      "\n",
      "\n",
      "2016-07-09 \n",
      "\n",
      "\n",
      "2016-07-10 \n",
      "\n",
      "\n",
      "2016-07-11 \n",
      "\n",
      "\n",
      "2016-07-12 \n",
      "\n",
      "\n",
      "2016-07-13 \n",
      "\n",
      "\n",
      "2016-07-14 \n",
      "\n",
      "\n",
      "2016-07-15 \n",
      "\n",
      "\n",
      "2016-07-16 \n",
      "\n",
      "\n",
      "2016-07-17 \n",
      "\n",
      "\n",
      "2016-07-18 \n",
      "\n",
      "\n",
      "2016-07-19 \n",
      "\n",
      "\n",
      "2016-07-20 \n",
      "\n",
      "\n",
      "2016-07-21 \n",
      "\n",
      "\n",
      "2016-07-22 \n",
      "\n",
      "\n",
      "2016-07-23 \n",
      "\n",
      "\n",
      "2016-07-24 \n",
      "\n",
      "\n",
      "2016-07-25 \n",
      "\n",
      "\n",
      "2016-07-26 \n",
      "\n",
      "\n",
      "2016-07-27 \n",
      "\n",
      "\n",
      "2016-07-28 \n",
      "\n",
      "\n",
      "2016-07-29 \n",
      "\n",
      "\n",
      "2016-07-30 \n",
      "\n",
      "\n",
      "2016-07-31 \n",
      "\n",
      "\n",
      "2016-08-01 \n",
      "\n",
      "\n",
      "2016-08-02 \n",
      "\n",
      "\n",
      "2016-08-03 \n",
      "\n",
      "\n",
      "2016-08-04 \n",
      "\n",
      "\n",
      "2016-08-05 \n",
      "\n",
      "\n",
      "2016-08-06 \n",
      "\n",
      "\n",
      "2016-08-07 \n",
      "\n",
      "\n",
      "2016-08-08 \n",
      "\n",
      "\n",
      "2016-08-09 \n",
      "\n",
      "\n",
      "2016-08-10 \n",
      "\n",
      "\n",
      "2016-08-11 \n",
      "\n",
      "\n",
      "2016-08-12 \n",
      "\n",
      "\n",
      "2016-08-13 \n",
      "\n",
      "\n",
      "2016-08-14 \n",
      "\n",
      "\n",
      "2016-08-15 \n",
      "\n",
      "\n",
      "2016-08-16 \n",
      "\n",
      "\n",
      "2016-08-17 \n",
      "\n",
      "\n",
      "2016-08-18 \n",
      "\n",
      "\n",
      "2016-08-19 \n",
      "\n",
      "\n",
      "2016-08-20 \n",
      "\n",
      "\n",
      "2016-08-21 \n",
      "\n",
      "\n",
      "2016-08-22 \n",
      "\n",
      "\n",
      "2016-08-23 \n",
      "\n",
      "\n",
      "2016-08-24 \n",
      "\n",
      "\n",
      "2016-08-25 \n",
      "\n",
      "\n",
      "2016-08-27 \n",
      "\n",
      "\n",
      "2016-08-28 \n",
      "\n",
      "\n",
      "time \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, item in gk:\n",
    "    print(key, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2017-01-01'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_group\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2017-01-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:817\u001b[0m, in \u001b[0;36mBaseGroupBy.get_group\u001b[0;34m(self, name, obj)\u001b[0m\n\u001b[1;32m    815\u001b[0m inds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_index(name)\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inds):\n\u001b[0;32m--> 817\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(name)\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(inds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis)\n",
      "\u001b[0;31mKeyError\u001b[0m: '2017-01-01'"
     ]
    }
   ],
   "source": [
    "gk.get_group('2017-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = datetime.fromtimestamp(int(1675435079)).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-2-3\n"
     ]
    }
   ],
   "source": [
    "print(str(cc.year)+\"-\"+str(cc.month)+\"-\"+str(cc.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 2, 3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "InfluxDBClientError",
     "evalue": "401: {\"code\":\"unauthorized\",\"message\":\"Unauthorized\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInfluxDBClientError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Create the database if it does not exist\u001b[39;00m\n\u001b[1;32m      9\u001b[0m database_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatabase_name\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m database_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [db[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m db \u001b[38;5;129;01min\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_list_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]:\n\u001b[1;32m     11\u001b[0m     client\u001b[38;5;241m.\u001b[39mcreate_database(database_name)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Switch to the desired database\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/influxdb/client.py:704\u001b[0m, in \u001b[0;36mInfluxDBClient.get_list_database\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_list_database\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the list of databases in InfluxDB.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \n\u001b[1;32m    693\u001b[0m \u001b[38;5;124;03m    :returns: all databases in InfluxDB\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;124;03m        [{u'name': u'db1'}, {u'name': u'db2'}, {u'name': u'db3'}]\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSHOW DATABASES\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_points())\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/influxdb/client.py:521\u001b[0m, in \u001b[0;36mInfluxDBClient.query\u001b[0;34m(self, query, params, bind_params, epoch, expected_response_code, database, raise_errors, chunked, chunk_size, method)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m query\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m into \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m query\u001b[38;5;241m.\u001b[39mlower():\n\u001b[1;32m    519\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 521\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpected_response_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_response_code\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39m_msgpack\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/influxdb/client.py:378\u001b[0m, in \u001b[0;36mInfluxDBClient.request\u001b[0;34m(self, url, method, params, data, stream, expected_response_code, headers)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m     err_msg \u001b[38;5;241m=\u001b[39m reformat_error(response)\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InfluxDBClientError(err_msg, response\u001b[38;5;241m.\u001b[39mstatus_code)\n",
      "\u001b[0;31mInfluxDBClientError\u001b[0m: 401: {\"code\":\"unauthorized\",\"message\":\"Unauthorized\"}"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from influxdb import InfluxDBClient\n",
    "\n",
    "# Connect to InfluxDB with a token\n",
    "client = InfluxDBClient(host='localhost', port=8086)\n",
    "\n",
    "# Create the database if it does not exist\n",
    "database_name = 'database_name'\n",
    "if database_name not in [db['name'] for db in client.get_list_database()]:\n",
    "    client.create_database(database_name)\n",
    "\n",
    "# Switch to the desired database\n",
    "client.switch_database(database_name)\n",
    "\n",
    "# Get all tsv.gz files in a folder\n",
    "folder_path = '/path/to/folder'\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.tsv.gz'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Read the tsv.gz file using pandas\n",
    "        df = pd.read_csv(file_path, sep='\\t', compression='gzip')\n",
    "        # Extract the date from the filename\n",
    "        date = filename.split('_')[2][:8]\n",
    "        # Convert the date to the desired format\n",
    "        date = f\"{date[:4]}-{date[4:6]}-{date[6:8]}\"\n",
    "        # Create a list of dictionaries to store the data in the format required by InfluxDB\n",
    "        data = []\n",
    "        for i in range(len(df)):\n",
    "            data.append({\n",
    "                \"measurement\": filename.split('_')[0] + \"_\" + filename.split('_')[1],\n",
    "                \"time\": date,\n",
    "                \"fields\": {\n",
    "                    \"time\": df.iloc[i]['time'],\n",
    "                    \"size\": df.iloc[i]['size'],\n",
    "                    \"fee\": df.iloc[i]['fee'],\n",
    "                    \"block_id\": df.iloc[i]['block_id']\n",
    "                }\n",
    "            })\n",
    "        # Write the data to InfluxDB\n",
    "        client.write_points(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InfluxDBClient(host='localhost', port=8086, username='amitutta121', password='64059720')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "InfluxDBClientError",
     "evalue": "401: {\"code\":\"unauthorized\",\"message\":\"Unauthorized\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInfluxDBClientError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_database\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthesis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/influxdb/client.py:746\u001b[0m, in \u001b[0;36mInfluxDBClient.create_database\u001b[0;34m(self, dbname)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_database\u001b[39m(\u001b[38;5;28mself\u001b[39m, dbname):\n\u001b[1;32m    741\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a new database in InfluxDB.\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \n\u001b[1;32m    743\u001b[0m \u001b[38;5;124;03m    :param dbname: the name of the database to create\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;124;03m    :type dbname: str\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 746\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCREATE DATABASE \u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquote_ident\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdbname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/influxdb/client.py:521\u001b[0m, in \u001b[0;36mInfluxDBClient.query\u001b[0;34m(self, query, params, bind_params, epoch, expected_response_code, database, raise_errors, chunked, chunk_size, method)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m query\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m into \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m query\u001b[38;5;241m.\u001b[39mlower():\n\u001b[1;32m    519\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 521\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpected_response_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_response_code\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39m_msgpack\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject1/venv/lib/python3.8/site-packages/influxdb/client.py:378\u001b[0m, in \u001b[0;36mInfluxDBClient.request\u001b[0;34m(self, url, method, params, data, stream, expected_response_code, headers)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m     err_msg \u001b[38;5;241m=\u001b[39m reformat_error(response)\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InfluxDBClientError(err_msg, response\u001b[38;5;241m.\u001b[39mstatus_code)\n",
      "\u001b[0;31mInfluxDBClientError\u001b[0m: 401: {\"code\":\"unauthorized\",\"message\":\"Unauthorized\"}"
     ]
    }
   ],
   "source": [
    "client.create_database(\"thesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (571045817.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    client1 = InfluxDBClient(host='localhost', port=8086, username='amitutta121', password='64059720' ssl=True, verify_ssl=True)\u001b[0m\n\u001b[0m                                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "client1 = InfluxDBClient(host='localhost', port=8086, username='amitutta121', password='64059720' ssl=True, verify_ssl=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
